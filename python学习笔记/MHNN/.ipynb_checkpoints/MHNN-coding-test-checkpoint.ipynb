{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "F:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "F:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "F:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "F:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "F:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "F:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "F:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "F:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "F:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "F:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "F:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "F:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Concatenate, Dense, LSTM, Input, concatenate,Conv2D,MaxPooling2D,BatchNormalization,UpSampling2D,Lambda\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(image, cm='hot') :\n",
    "    sns.set()\n",
    "    sns.heatmap(image, cmap=cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_x = K.placeholder(dtype=tf.float32,shape=(None, 200, 200, 4))\n",
    "# tf_y = K.placeholder(dtype=tf.float32,shape=(None, 200, 200, 1))\n",
    "# tf_z = K.placeholder(dtype=tf.float32,shape=(None, 7))\n",
    "# is_t = K.placeholder(dtype=tf.bool,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设定随机数\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# 类别个数\n",
    "num_classes = None\n",
    "# 图片大小\n",
    "lng = 200\n",
    "# 属性维度\n",
    "att_d = 4\n",
    "int_shp = (lng, lng, att_d)\n",
    "cut_num = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading train_x\n",
      "loading train_y\n",
      "loading train_z\n",
      "loading pred_x\n",
      "loading pred_y\n",
      "loading pred_z\n"
     ]
    }
   ],
   "source": [
    "pred_x_name = 'E:/20190924_match_pro/MHNN/data/scale_data/pred_x2.npy'\n",
    "pred_y_name = 'E:/20190924_match_pro/MHNN/data/scale_data/pred_y2.npy'\n",
    "pred_z_name = 'E:/20190924_match_pro/MHNN/data/scale_data/pred_z2.npy'\n",
    "train_x_name= 'E:/20190924_match_pro/MHNN/data/scale_data/train_x2.npy'\n",
    "train_y_name= 'E:/20190924_match_pro/MHNN/data/scale_data/train_y2.npy'\n",
    "train_z_name= 'E:/20190924_match_pro/MHNN/data/scale_data/train_z2.npy'\n",
    "\n",
    "print('loading train_x')\n",
    "train_x = np.load(train_x_name)\n",
    "print('loading train_y')\n",
    "train_y = np.load(train_y_name)\n",
    "print('loading train_z')\n",
    "train_z = np.load(train_z_name)\n",
    "print('loading pred_x')\n",
    "pred_x  = np.load(pred_x_name)\n",
    "print('loading pred_y')\n",
    "pred_y  = np.load(pred_y_name)\n",
    "print('loading pred_z')\n",
    "pred_z  = np.load(pred_z_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义模型\n",
    "def MHNN_model():    \n",
    "  \n",
    "    main_input = Input(shape = (200,200,4), name='main_input')\n",
    "    \n",
    "    conv1 = Conv2D(filters=16, strides=1, kernel_size=3,activation='relu', padding='same')(main_input)\n",
    "    conv1 = Conv2D(filters=16, strides=1, kernel_size=3,activation='relu', padding='same')(conv1)\n",
    "    conv1 = Conv2D(filters=16, strides=1, kernel_size=3,activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    BN1   = BatchNormalization()(pool1)\n",
    "    \n",
    "    conv2 = Conv2D(filters=64, strides=1, kernel_size=3,activation='relu', padding='same')(BN1)\n",
    "    conv2 = Conv2D(filters=64, strides=1, kernel_size=3,activation='relu', padding='same')(conv2)\n",
    "    conv2 = Conv2D(filters=64, strides=1, kernel_size=3,activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    BN2   = BatchNormalization()(pool2)\n",
    "    \n",
    "    conv3 = Conv2D(filters=64, strides=1, kernel_size=3,activation='relu', padding='same')(BN2)\n",
    "    conv3 = Conv2D(filters=64, strides=1, kernel_size=3,activation='relu', padding='same')(conv3)\n",
    "    conv3 = Conv2D(filters=64, strides=1, kernel_size=3,activation='relu', padding='same')(conv3)\n",
    "    BN3   = BatchNormalization()(conv3)\n",
    "    \n",
    "    up1   = UpSampling2D(size = (2,2))(BN3)\n",
    "    up1   = Conv2D(filters=64, strides=1, kernel_size=3,activation='relu', padding='same')(up1)\n",
    "    \n",
    "    merge1 = concatenate([conv2,up1], axis = 3)\n",
    "    \n",
    "    conv4 = Conv2D(filters=64, strides=1, kernel_size=3,activation='relu', padding='same')(merge1)\n",
    "    conv4 = Conv2D(filters=64, strides=1, kernel_size=3,activation='relu', padding='same')(conv4)\n",
    "    conv4 = Conv2D(filters=64, strides=1, kernel_size=3,activation='relu', padding='same')(conv4)\n",
    "    \n",
    "    up2   = UpSampling2D(size = (2,2))(conv4)\n",
    "    up2   = Conv2D(filters=16, strides=1, kernel_size=3,activation='relu', padding='same')(up2)\n",
    "    \n",
    "    conv5 = Conv2D(filters=16, strides=1, kernel_size=3,activation='relu', padding='same')(up2)\n",
    "    conv5 = Conv2D(filters=16, strides=1, kernel_size=3,activation='relu', padding='same')(conv5)\n",
    "    conv5 = Conv2D(filters=16, strides=1, kernel_size=3,activation='relu', padding='same')(conv5)\n",
    "    conv5 = Conv2D(filters=4, strides=1, kernel_size=3,activation='relu', padding='same')(conv5)\n",
    "    \n",
    "    output1 = Conv2D(filters=1, strides=1, kernel_size=3, activation = 'sigmoid', padding = 'same')(conv5)\n",
    "    \n",
    "#     output1_ = tf.reshape(output1, [-1, conv5.shape[1]*conv5.shape[2]])\n",
    "#     tf_y_    = tf.reshape(tf_y, [-1, conv5.shape[1]*conv5.shape[2]])\n",
    "\n",
    "    tf_x_input = Input(shape = (200,200,4))\n",
    "    tf_x       = Conv2D(filters=4, strides=1, kernel_size=3,activation='relu', padding='same')(tf_x_input)\n",
    "    merge2     = concatenate([tf_x,output1], axis = 3)\n",
    "#     merge2 = Lambda(lambda x: concatenate([tf_x,output1], axis = 3))\n",
    "    \n",
    "    conv6 = Conv2D(filters=16, strides=1, kernel_size=3,activation='relu', padding='same')(merge2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    model = Model(inputs=[main_input,tf_x_input], outputs=[conv6])\n",
    "    model.compile(loss='mse', metrics=['accuracy'], optimizer='rmsprop')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, 200, 200, 4)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_565 (Conv2D)             (None, 200, 200, 16) 592         main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_566 (Conv2D)             (None, 200, 200, 16) 2320        conv2d_565[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_567 (Conv2D)             (None, 200, 200, 16) 2320        conv2d_566[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_59 (MaxPooling2D) (None, 100, 100, 16) 0           conv2d_567[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 100, 100, 16) 64          max_pooling2d_59[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_568 (Conv2D)             (None, 100, 100, 64) 9280        batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_569 (Conv2D)             (None, 100, 100, 64) 36928       conv2d_568[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_570 (Conv2D)             (None, 100, 100, 64) 36928       conv2d_569[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_60 (MaxPooling2D) (None, 50, 50, 64)   0           conv2d_570[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 50, 50, 64)   256         max_pooling2d_60[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_571 (Conv2D)             (None, 50, 50, 64)   36928       batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_572 (Conv2D)             (None, 50, 50, 64)   36928       conv2d_571[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_573 (Conv2D)             (None, 50, 50, 64)   36928       conv2d_572[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 50, 50, 64)   256         conv2d_573[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_58 (UpSampling2D) (None, 100, 100, 64) 0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_574 (Conv2D)             (None, 100, 100, 64) 36928       up_sampling2d_58[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 100, 100, 128 0           conv2d_570[0][0]                 \n",
      "                                                                 conv2d_574[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_575 (Conv2D)             (None, 100, 100, 64) 73792       concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_576 (Conv2D)             (None, 100, 100, 64) 36928       conv2d_575[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_577 (Conv2D)             (None, 100, 100, 64) 36928       conv2d_576[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_59 (UpSampling2D) (None, 200, 200, 64) 0           conv2d_577[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_578 (Conv2D)             (None, 200, 200, 16) 9232        up_sampling2d_59[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_579 (Conv2D)             (None, 200, 200, 16) 2320        conv2d_578[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_580 (Conv2D)             (None, 200, 200, 16) 2320        conv2d_579[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_581 (Conv2D)             (None, 200, 200, 16) 2320        conv2d_580[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 200, 200, 4)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_582 (Conv2D)             (None, 200, 200, 4)  580         conv2d_581[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_584 (Conv2D)             (None, 200, 200, 4)  148         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_583 (Conv2D)             (None, 200, 200, 1)  37          conv2d_582[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 200, 200, 5)  0           conv2d_584[0][0]                 \n",
      "                                                                 conv2d_583[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_585 (Conv2D)             (None, 200, 200, 16) 736         concatenate_41[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 401,997\n",
      "Trainable params: 401,709\n",
      "Non-trainable params: 288\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = MHNN_model()\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
