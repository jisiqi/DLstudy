{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "F:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "F:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "F:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "F:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "F:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "F:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "F:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "F:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "F:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "F:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "F:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "F:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Concatenate, Dense, LSTM, Input, concatenate,Conv2D,MaxPooling2D,BatchNormalization,UpSampling2D,Lambda\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(image, cm='hot') :\n",
    "    sns.set()\n",
    "    sns.heatmap(image, cmap=cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_x = K.placeholder(dtype=tf.float32,shape=(None, 200, 200, 4))\n",
    "# tf_y = K.placeholder(dtype=tf.float32,shape=(None, 200, 200, 1))\n",
    "# tf_z = K.placeholder(dtype=tf.float32,shape=(None, 7))\n",
    "# is_t = K.placeholder(dtype=tf.bool,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设定随机数\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# 类别个数\n",
    "num_classes = None\n",
    "# 图片大小\n",
    "lng = 200\n",
    "# 属性维度\n",
    "att_d = 4\n",
    "int_shp = (lng, lng, att_d)\n",
    "cut_num = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading train_x\n",
      "loading train_y\n",
      "loading train_z\n",
      "loading pred_x\n",
      "loading pred_y\n",
      "loading pred_z\n"
     ]
    }
   ],
   "source": [
    "pred_x_name = 'E:/20190924_match_pro/MHNN/data/scale_data/pred_x2.npy'\n",
    "pred_y_name = 'E:/20190924_match_pro/MHNN/data/scale_data/pred_y2.npy'\n",
    "pred_z_name = 'E:/20190924_match_pro/MHNN/data/scale_data/pred_z2.npy'\n",
    "train_x_name= 'E:/20190924_match_pro/MHNN/data/scale_data/train_x2.npy'\n",
    "train_y_name= 'E:/20190924_match_pro/MHNN/data/scale_data/train_y2.npy'\n",
    "train_z_name= 'E:/20190924_match_pro/MHNN/data/scale_data/train_z2.npy'\n",
    "\n",
    "print('loading train_x')\n",
    "train_x = np.load(train_x_name)\n",
    "print('loading train_y')\n",
    "train_y = np.load(train_y_name)\n",
    "print('loading train_z')\n",
    "train_z = np.load(train_z_name)\n",
    "print('loading pred_x')\n",
    "pred_x  = np.load(pred_x_name)\n",
    "print('loading pred_y')\n",
    "pred_y  = np.load(pred_y_name)\n",
    "print('loading pred_z')\n",
    "pred_z  = np.load(pred_z_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义模型\n",
    "def MHNN_model():    \n",
    "  \n",
    "    main_input = Input(shape = (200,200,4), name='main_input')\n",
    "    \n",
    "    conv1 = Conv2D(filters=16, strides=1, kernel_size=3,activation='relu', padding='same')(main_input)\n",
    "    conv1 = Conv2D(filters=16, strides=1, kernel_size=3,activation='relu', padding='same')(conv1)\n",
    "    conv1 = Conv2D(filters=16, strides=1, kernel_size=3,activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    BN1   = BatchNormalization()(pool1)\n",
    "    \n",
    "    conv2 = Conv2D(filters=64, strides=1, kernel_size=3,activation='relu', padding='same')(BN1)\n",
    "    conv2 = Conv2D(filters=64, strides=1, kernel_size=3,activation='relu', padding='same')(conv2)\n",
    "    conv2 = Conv2D(filters=64, strides=1, kernel_size=3,activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    BN2   = BatchNormalization()(pool2)\n",
    "    \n",
    "    conv3 = Conv2D(filters=64, strides=1, kernel_size=3,activation='relu', padding='same')(BN2)\n",
    "    conv3 = Conv2D(filters=64, strides=1, kernel_size=3,activation='relu', padding='same')(conv3)\n",
    "    conv3 = Conv2D(filters=64, strides=1, kernel_size=3,activation='relu', padding='same')(conv3)\n",
    "    BN3   = BatchNormalization()(conv3)\n",
    "    \n",
    "    up1   = UpSampling2D(size = (2,2))(BN3)\n",
    "    up1   = Conv2D(filters=64, strides=1, kernel_size=3,activation='relu', padding='same')(up1)\n",
    "    \n",
    "    merge1 = concatenate([conv2,up1], axis = 3)\n",
    "    \n",
    "    conv4 = Conv2D(filters=64, strides=1, kernel_size=3,activation='relu', padding='same')(merge1)\n",
    "    conv4 = Conv2D(filters=64, strides=1, kernel_size=3,activation='relu', padding='same')(conv4)\n",
    "    conv4 = Conv2D(filters=64, strides=1, kernel_size=3,activation='relu', padding='same')(conv4)\n",
    "    \n",
    "    up2   = UpSampling2D(size = (2,2))(conv4)\n",
    "    up2   = Conv2D(filters=16, strides=1, kernel_size=3,activation='relu', padding='same')(up2)\n",
    "    \n",
    "    conv5 = Conv2D(filters=16, strides=1, kernel_size=3,activation='relu', padding='same')(up2)\n",
    "    conv5 = Conv2D(filters=16, strides=1, kernel_size=3,activation='relu', padding='same')(conv5)\n",
    "    conv5 = Conv2D(filters=16, strides=1, kernel_size=3,activation='relu', padding='same')(conv5)\n",
    "    conv5 = Conv2D(filters=4, strides=1, kernel_size=3,activation='relu', padding='same')(conv5)\n",
    "    \n",
    "    output1 = Conv2D(filters=1, strides=1, kernel_size=3, activation = 'sigmoid', padding = 'same')(conv5)\n",
    "    \n",
    "#     output1_ = tf.reshape(output1, [-1, conv5.shape[1]*conv5.shape[2]])\n",
    "#     tf_y_    = tf.reshape(tf_y, [-1, conv5.shape[1]*conv5.shape[2]])\n",
    "\n",
    "    \n",
    "#     tf_x       = Conv2D(filters=4, strides=1, kernel_size=3,activation='relu', padding='same')(tf_x_input)\n",
    "    tf_x   = Input(shape = (200,200,4))\n",
    "    merge2 = concatenate([tf_x,output1], axis = 3)\n",
    "#     merge2 = Lambda(lambda x: concatenate([tf_x,output1], axis = 3))\n",
    "    \n",
    "    conv6 = Conv2D(filters=16, strides=1, kernel_size=3,activation='relu', padding='same')(merge2)\n",
    "    conv6 = Conv2D(filters=16, strides=1, kernel_size=3,activation='relu', padding='same')(conv6)\n",
    "    conv6 = Conv2D(filters=16, strides=1, kernel_size=3,activation='relu', padding='same')(conv6)\n",
    "    pool6 = MaxPooling2D(pool_size=(2, 2))(conv6)\n",
    "    BN6   = BatchNormalization()(pool6)\n",
    "    \n",
    "    merge3 = concatenate([pool6, pool1, conv4], 3) # [pool5, pool1, conv4]\n",
    "    \n",
    "    conv6 = Conv2D(filters=16, strides=1, kernel_size=3,activation='relu', padding='same')(merge2)\n",
    "    conv6 = Conv2D(filters=16, strides=1, kernel_size=3,activation='relu', padding='same')(conv6)\n",
    "    conv6 = Conv2D(filters=16, strides=1, kernel_size=3,activation='relu', padding='same')(conv6)\n",
    "    pool6 = MaxPooling2D(pool_size=(2, 2))(conv6)\n",
    "    \n",
    "    model = Model(inputs=[main_input,tf_x], outputs=[merge3])\n",
    "    model.compile(loss='mse', metrics=['accuracy'], optimizer='rmsprop')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_16\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, 200, 200, 4)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_628 (Conv2D)             (None, 200, 200, 16) 592         main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_629 (Conv2D)             (None, 200, 200, 16) 2320        conv2d_628[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_630 (Conv2D)             (None, 200, 200, 16) 2320        conv2d_629[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_66 (MaxPooling2D) (None, 100, 100, 16) 0           conv2d_630[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 100, 100, 16) 64          max_pooling2d_66[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_631 (Conv2D)             (None, 100, 100, 64) 9280        batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_632 (Conv2D)             (None, 100, 100, 64) 36928       conv2d_631[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_633 (Conv2D)             (None, 100, 100, 64) 36928       conv2d_632[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_67 (MaxPooling2D) (None, 50, 50, 64)   0           conv2d_633[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 50, 50, 64)   256         max_pooling2d_67[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_634 (Conv2D)             (None, 50, 50, 64)   36928       batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_635 (Conv2D)             (None, 50, 50, 64)   36928       conv2d_634[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_636 (Conv2D)             (None, 50, 50, 64)   36928       conv2d_635[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 50, 50, 64)   256         conv2d_636[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_64 (UpSampling2D) (None, 100, 100, 64) 0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_637 (Conv2D)             (None, 100, 100, 64) 36928       up_sampling2d_64[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)    (None, 100, 100, 128 0           conv2d_633[0][0]                 \n",
      "                                                                 conv2d_637[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_638 (Conv2D)             (None, 100, 100, 64) 73792       concatenate_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_639 (Conv2D)             (None, 100, 100, 64) 36928       conv2d_638[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_640 (Conv2D)             (None, 100, 100, 64) 36928       conv2d_639[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_65 (UpSampling2D) (None, 200, 200, 64) 0           conv2d_640[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_641 (Conv2D)             (None, 200, 200, 16) 9232        up_sampling2d_65[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_642 (Conv2D)             (None, 200, 200, 16) 2320        conv2d_641[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_643 (Conv2D)             (None, 200, 200, 16) 2320        conv2d_642[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_644 (Conv2D)             (None, 200, 200, 16) 2320        conv2d_643[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_645 (Conv2D)             (None, 200, 200, 4)  580         conv2d_644[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, 200, 200, 4)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_646 (Conv2D)             (None, 200, 200, 1)  37          conv2d_645[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_48 (Concatenate)    (None, 200, 200, 5)  0           input_7[0][0]                    \n",
      "                                                                 conv2d_646[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_647 (Conv2D)             (None, 200, 200, 16) 736         concatenate_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_648 (Conv2D)             (None, 200, 200, 16) 2320        conv2d_647[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_649 (Conv2D)             (None, 200, 200, 16) 2320        conv2d_648[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_68 (MaxPooling2D) (None, 100, 100, 16) 0           conv2d_649[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_49 (Concatenate)    (None, 100, 100, 96) 0           max_pooling2d_68[0][0]           \n",
      "                                                                 max_pooling2d_66[0][0]           \n",
      "                                                                 conv2d_640[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 406,489\n",
      "Trainable params: 406,201\n",
      "Non-trainable params: 288\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = MHNN_model()\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
