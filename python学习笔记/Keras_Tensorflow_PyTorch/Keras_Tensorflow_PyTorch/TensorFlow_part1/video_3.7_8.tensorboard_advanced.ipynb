{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./graphs/dl_banner.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard可视化\n",
    "#### \\[稀牛学院 x 网易云课程\\]《深度学习工程师(实战)》课程资料 by [@寒小阳](https://blog.csdn.net/han_xiaoyang)\n",
    "\n",
    "Tensorboard是一个非常好用的可视化工具，可以配合tensorflow一起去完成神经网络训练，在网络训练过程中，可以实时对训练中间状态进行可视化观察。\n",
    "![](./graphs/Tensorboard.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.导入工具库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.设定超参数\n",
    "#### \\[稀牛学院 x 网易云课程\\]《深度学习工程师(实战)》课程资料 by [@寒小阳](https://blog.csdn.net/han_xiaoyang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练参数\n",
    "learning_rate = 0.01 # 学习率\n",
    "training_epochs = 25 # 总迭代轮次\n",
    "batch_size = 100 # 一批数据大小\n",
    "display_step = 1 # 信息展示间隔频度\n",
    "logs_path = '/tmp/tensorflow_logs/' # 日志存储地址\n",
    "\n",
    "# 网络参数\n",
    "n_hidden_1 = 256 # 第1个隐层神经元个数\n",
    "n_hidden_2 = 256 # 第2个隐层神经元个数\n",
    "n_input = 784 # MNIST数据输入(28*28=784)\n",
    "n_classes = 10 # MNIST总共有0-9这10个类别\n",
    "\n",
    "# 占位符\n",
    "x = tf.placeholder(tf.float32, [None, 784], name='InputData')\n",
    "y = tf.placeholder(tf.float32, [None, 10], name='LabelData')\n",
    "\n",
    "# 变量\n",
    "weights = {\n",
    "    'w1': tf.Variable(tf.random_normal([n_input, n_hidden_1]), name='W1'),\n",
    "    'w2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2]), name='W2'),\n",
    "    'w3': tf.Variable(tf.random_normal([n_hidden_2, n_classes]), name='W3')\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1]), name='b1'),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2]), name='b2'),\n",
    "    'b3': tf.Variable(tf.random_normal([n_classes]), name='b3')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-b5a6f5f5ed36>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting /data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /data/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "# 导入 MNIST 数据集\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/data/Deep_learning/MNIST_data\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.构建模型\n",
    "#### \\[稀牛学院 x 网易云课程\\]《深度学习工程师(实战)》课程资料 by [@寒小阳](https://blog.csdn.net/han_xiaoyang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建模型\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    "    # WX+b再通过非线性变换\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    # 为了在Tensorboard中做可视化，summary一下\n",
    "    tf.summary.histogram(\"relu1\", layer_1)\n",
    "    # WX+b再通过非线性变换\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    # 为了在Tensorboard中做可视化，再次summary一下\n",
    "    tf.summary.histogram(\"relu2\", layer_2)\n",
    "    # 全连接层\n",
    "    out_layer = tf.add(tf.matmul(layer_2, weights['w3']), biases['b3'])\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.计算损失与优化\n",
    "#### \\[稀牛学院 x 网易云课程\\]《深度学习工程师(实战)》课程资料 by [@寒小阳](https://blog.csdn.net/han_xiaoyang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-cf0f5b0ca0af>:8: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "INFO:tensorflow:Summary name W1:0 is illegal; using W1_0 instead.\n",
      "INFO:tensorflow:Summary name W2:0 is illegal; using W2_0 instead.\n",
      "INFO:tensorflow:Summary name W3:0 is illegal; using W3_0 instead.\n",
      "INFO:tensorflow:Summary name b1:0 is illegal; using b1_0 instead.\n",
      "INFO:tensorflow:Summary name b2:0 is illegal; using b2_0 instead.\n",
      "INFO:tensorflow:Summary name b3:0 is illegal; using b3_0 instead.\n",
      "INFO:tensorflow:Summary name W1:0/gradient is illegal; using W1_0/gradient instead.\n",
      "INFO:tensorflow:Summary name W2:0/gradient is illegal; using W2_0/gradient instead.\n",
      "INFO:tensorflow:Summary name W3:0/gradient is illegal; using W3_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b1:0/gradient is illegal; using b1_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b2:0/gradient is illegal; using b2_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b3:0/gradient is illegal; using b3_0/gradient instead.\n"
     ]
    }
   ],
   "source": [
    "# 把不同的op分到不同scope里，这样可视化会更清晰\n",
    "with tf.name_scope('Model'):\n",
    "    # 构建多层感知器\n",
    "    pred = multilayer_perceptron(x, weights, biases)\n",
    "\n",
    "with tf.name_scope('Loss'):\n",
    "    # Softmax交叉熵损失\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "\n",
    "with tf.name_scope('SGD'):\n",
    "    # 梯度下降\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    # gradient/梯度\n",
    "    grads = tf.gradients(loss, tf.trainable_variables())\n",
    "    grads = list(zip(grads, tf.trainable_variables()))\n",
    "    apply_grads = optimizer.apply_gradients(grads_and_vars=grads)\n",
    "\n",
    "with tf.name_scope('Accuracy'):\n",
    "    # 准确率\n",
    "    acc = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    acc = tf.reduce_mean(tf.cast(acc, tf.float32))\n",
    "    \n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 构建loss的summary（是一个标量，用scalar）\n",
    "tf.summary.scalar(\"loss\", loss)\n",
    "# 构建accuracy的summary（是一个标量，用scalar）\n",
    "tf.summary.scalar(\"accuracy\", acc)\n",
    "# 构建变量的summary（用histogram）\n",
    "for var in tf.trainable_variables():\n",
    "    tf.summary.histogram(var.name, var)\n",
    "# 构建gradient的summary（用histogram）\n",
    "for grad, var in grads:\n",
    "    tf.summary.histogram(var.name + '/gradient', grad)\n",
    "\n",
    "# 注意这一步，Merge所有的summaries\n",
    "merged_summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.在session当中完成计算图计算(损失计算与优化、参数更新迭代)\n",
    "#### \\[稀牛学院 x 网易云课程\\]《深度学习工程师(实战)》课程资料 by [@寒小阳](https://blog.csdn.net/han_xiaoyang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0001轮 当前损失为 60.288031075\n",
      "第0002轮 当前损失为 13.371679590\n",
      "第0003轮 当前损失为 8.301543406\n",
      "第0004轮 当前损失为 5.773074016\n",
      "第0005轮 当前损失为 4.293483163\n",
      "第0006轮 当前损失为 3.378652347\n",
      "第0007轮 当前损失为 2.670954888\n",
      "第0008轮 当前损失为 2.178419899\n",
      "第0009轮 当前损失为 1.797803634\n",
      "第0010轮 当前损失为 1.516569294\n",
      "第0011轮 当前损失为 1.279891578\n",
      "第0012轮 当前损失为 1.107888400\n",
      "第0013轮 当前损失为 0.933186120\n",
      "第0014轮 当前损失为 0.806697653\n",
      "第0015轮 当前损失为 0.701871073\n",
      "第0016轮 当前损失为 0.611931115\n",
      "第0017轮 当前损失为 0.529205006\n",
      "第0018轮 当前损失为 0.465786743\n",
      "第0019轮 当前损失为 0.417982321\n",
      "第0020轮 当前损失为 0.362660631\n",
      "第0021轮 当前损失为 0.324746763\n",
      "第0022轮 当前损失为 0.284380918\n",
      "第0023轮 当前损失为 0.257371605\n",
      "第0024轮 当前损失为 0.224821891\n",
      "第0025轮 当前损失为 0.195312340\n",
      "训练完成！\n",
      "准确率: 0.9279\n",
      "Run the command line:\n",
      "--> tensorboard --logdir=/tmp/tensorflow_logs \n",
      "Then open http://0.0.0.0:6006/ into your web browser\n"
     ]
    }
   ],
   "source": [
    "# 在session中开始训练\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # 初始化所有变量\n",
    "    sess.run(init)\n",
    "\n",
    "    # 要把log写出去，以便Tensorboard可视化\n",
    "    summary_writer = tf.summary.FileWriter(logs_path,\n",
    "                                            graph=tf.get_default_graph())\n",
    "\n",
    "    # 训练的迭代过程\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        # 遍历所有batches\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            _, c, summary = sess.run([apply_grads, loss, merged_summary_op],\n",
    "                                     feed_dict={x: batch_xs, y: batch_ys})\n",
    "            # 每一轮写入日志\n",
    "            summary_writer.add_summary(summary, epoch * total_batch + i)\n",
    "            # 计算平均损失\n",
    "            avg_cost += c / total_batch\n",
    "        # 打印中间结果展示\n",
    "        if (epoch+1) % display_step == 0:\n",
    "            print(\"第%04d轮\" % (epoch+1), \"当前损失为\", \"{:.9f}\".format(avg_cost))\n",
    "\n",
    "    print(\"训练完成！\")\n",
    "\n",
    "    # 测试集准确率\n",
    "    print(\"准确率:\", acc.eval({x: mnist.test.images, y: mnist.test.labels}))\n",
    "\n",
    "    print(\"Run the command line:\\n\" \\\n",
    "          \"--> tensorboard --logdir=/tmp/tensorflow_logs \" \\\n",
    "          \"\\nThen open http://0.0.0.0:6006/ into your web browser\")\n",
    "    \n",
    "# 说明：平台运行结果中的Tensorboard地址是私网地址，大家使用本地网络无法直接访问。\n",
    "#      如需使用Tensorboard，可以本地安装TensorFlow及Tensorboard，教程参考：https://blog.csdn.net/xq_nbu/article/details/80983969"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./graphs/Tensorboard1.png)\n",
    "![](./graphs/Tensorboard2.png)\n",
    "![](./graphs/Tensorboard3.png)\n",
    "![](./graphs/Tensorboard4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 版权归 © 稀牛学院 所有 保留所有权利\n",
    "![](./graphs/xiniu_neteasy.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
