{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../img/dl_banner.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用tensorflow low level API构建卷积神经网络\n",
    "#### \\[稀牛学院 x 网易云课程\\]《深度学习工程师(实战)》课程资料 by [@寒小阳](https://blog.csdn.net/han_xiaoyang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.知识背景：卷积神经网络\n",
    "卷积神经网络是一种在计算机视觉当中广泛应用的神经网络，其特殊的网络结构，包含卷积层、池化层等，能在共享参数的同时保证对图像特征的高效抽取。经典的卷积神经网络结构如下。\n",
    "![CNN](http://personal.ie.cuhk.edu.hk/~ccloy/project_target_code/images/fig3.png)\n",
    "\n",
    "## 0.问题背景：MNIST 手写数字\n",
    "#### \\[稀牛学院 x 网易云课程\\]《深度学习工程师(实战)》课程资料 by [@寒小阳](https://blog.csdn.net/han_xiaoyang)\n",
    "\n",
    "这是一个非常经典的问题，我们的对象是手写数字图片，我们需要根据手写数字图片的输入，构建线性的分类器(softmax分类器)去区分图片是手写数字0-9中的哪一个。这个问题的数据集，每一张图片的表示是长宽为28的矩阵，我们有时候会把它展开成784维的向量。MNIST手写数据集长成下面这样。\n",
    "\n",
    "![MNIST Dataset](http://neuralnetworksanddeeplearning.com/images/mnist_100_digits.png)\n",
    "\n",
    "更多的信息可以参考: http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.引入工具库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.设定超参数\n",
    "#### \\[稀牛学院 x 网易云课程\\]《深度学习工程师(实战)》课程资料 by [@寒小阳](https://blog.csdn.net/han_xiaoyang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练超参数\n",
    "learning_rate = 0.001\n",
    "num_steps = 2000\n",
    "batch_size = 128\n",
    "\n",
    "# 神经网络超参数\n",
    "num_input = 784 # MNIST数据输入(数据形状: 28*28)\n",
    "num_classes = 10 # MNIST总共类别(0-9总共10个手写数字)\n",
    "dropout = 0.25 # Dropout随机失活概率\n",
    "\n",
    "\n",
    "# 占位符\n",
    "X = tf.placeholder(tf.float32, [None, num_input])\n",
    "Y = tf.placeholder(tf.float32, [None, num_classes])\n",
    "keep_prob = tf.placeholder(tf.float32) # dropout (keep probability)\n",
    "\n",
    "# 变量\n",
    "weights = {\n",
    "    # 5x5 卷积核, 1 输入, 32 输出\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    # 5x5 卷积核, 32 输入, 64 输出\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    # 全连接, 7*7*64 输入, 1024 输出\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "    # 1024 输入, 10 输出(总共1类)\n",
    "    'out': tf.Variable(tf.random_normal([1024, num_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建卷积神经网络\n",
    "def conv_net(x_dict, n_classes, dropout, reuse, is_training):\n",
    "    \n",
    "    # 定义scope，以便在其内复用某些变量\n",
    "    with tf.variable_scope('ConvNet', reuse=reuse):\n",
    "        # 字典格式的输入，取出图像数据\n",
    "        x = x_dict['images']\n",
    "\n",
    "        # 原本MNIST数据输入是784维度向量\n",
    "        # 调整成 宽*高*通道数 的标准图片输入格式\n",
    "        # 总共是4个维度[Batch Size, Height, Width, Channel]，其中第一个维度-1表示暂时不确定一个batch多少张\n",
    "        x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "\n",
    "        # 先是卷积层，32个神经元，filter的形状为5*5\n",
    "        conv1 = tf.layers.conv2d(x, 32, 5, activation=tf.nn.relu)\n",
    "        # 最大池化层，2*2的滑窗大小，每次滑动的步长为2\n",
    "        conv1 = tf.layers.max_pooling2d(conv1, 2, 2)\n",
    "\n",
    "        # 再次添加卷积层(注意这里直接带上了relu做非线性变换)\n",
    "        conv2 = tf.layers.conv2d(conv1, 64, 3, activation=tf.nn.relu)\n",
    "        # 池化层\n",
    "        conv2 = tf.layers.max_pooling2d(conv2, 2, 2)\n",
    "\n",
    "        # 后面要接全连接层了，所以我们先把数据展平\n",
    "        fc1 = tf.contrib.layers.flatten(conv2)\n",
    "\n",
    "        # 接全连接层\n",
    "        fc1 = tf.layers.dense(fc1, 1024)\n",
    "        # 添加随机失活，以提高泛化能力\n",
    "        fc1 = tf.layers.dropout(fc1, rate=dropout, training=is_training)\n",
    "\n",
    "        # 接全连接层(神经元的个数和类别数对应)\n",
    "        out = tf.layers.dense(fc1, n_classes)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.计算损失与优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'weights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d7e3087c4efd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 构建卷积神经网络预估结果\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbiases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 定义损失与优化器\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'weights' is not defined"
     ]
    }
   ],
   "source": [
    "# 构建卷积神经网络预估结果\n",
    "logits = conv_net(X, weights, biases, keep_prob)\n",
    "prediction = tf.nn.softmax(logits)\n",
    "\n",
    "# 定义损失与优化器\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "\n",
    "# 评估模型\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# 初始化变量\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.在session当中完成计算图计算(损失计算与优化、参数更新迭代)\n",
    "#### \\[稀牛学院 x 网易云课程\\]《深度学习工程师(实战)》课程资料 by [@寒小阳](https://blog.csdn.net/han_xiaoyang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在session当中开始训练\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # 初始化\n",
    "    sess.run(init)\n",
    "\n",
    "    for step in range(1, num_steps+1):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        # 优化\n",
    "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y, keep_prob: dropout})\n",
    "        if step % display_step == 0 or step == 1:\n",
    "            # 计算准确率\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n",
    "                                                                 Y: batch_y,\n",
    "                                                                 keep_prob: 1.0})\n",
    "            print(\"第\" + str(step) + \"步, 一个minibatch上的损失为 \" + \\\n",
    "                  \"{:.4f}\".format(loss) + \", 训练准确率为 \" + \\\n",
    "                  \"{:.3f}\".format(acc))\n",
    "\n",
    "    print(\"完成训练！\")\n",
    "\n",
    "    # Calculate accuracy for 256 MNIST test images\n",
    "    print(\"测试准确率为 \", \\\n",
    "        sess.run(accuracy, feed_dict={X: mnist.test.images[:256],\n",
    "                                      Y: mnist.test.labels[:256],\n",
    "                                      keep_prob: 1.0}))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
