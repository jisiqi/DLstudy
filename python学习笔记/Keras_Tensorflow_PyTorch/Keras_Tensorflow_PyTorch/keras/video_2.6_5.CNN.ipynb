{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./img/dl_banner.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras卷积神经网络\n",
    "#### \\[稀牛学院 x 网易云课程\\]《深度学习工程师(实战)》课程资料 by [@寒小阳](https://blog.csdn.net/han_xiaoyang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.知识背景：卷积神经网络\n",
    "卷积神经网络是一种在计算机视觉当中广泛应用的神经网络，其特殊的网络结构，包含卷积层、池化层等，能在共享参数的同时保证对图像特征的高效抽取。经典的卷积神经网络结构如下。\n",
    "![CNN](http://personal.ie.cuhk.edu.hk/~ccloy/project_target_code/images/fig3.png)\n",
    "\n",
    "## 0.数据背景：Cifar-10\n",
    "cifar-10是一个很著名的实验数据集，该数据集共有60000张彩色图像，这些图像是32\\*32，分为10个类，每类6000张图。这里面有50000张用于训练，构成了5个训练批，每一批10000张图；另外10000用于测试，单独构成一批。测试批的数据里，取自10类中的每一类，每一类随机取1000张。抽剩下的就随机排列组成了训练批。注意一个训练批中的各类图像并不一定数量相同，总的来看训练批，每一类都有5000张图。\n",
    "![](./img/cifar-10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.加载数据\n",
    "#### \\[稀牛学院 x 网易云课程\\]《深度学习工程师(实战)》课程资料 by [@寒小阳](https://blog.csdn.net/han_xiaoyang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "from keras import Sequential\n",
    "from keras.layers import Conv2D, Activation, Flatten, Dense, Dropout, MaxPool2D\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意：直接通过“(X_train, y_train), (X_test, y_test) = cifar10.load_data()”加载数据需要科学上网。\n",
    "\n",
    "这里，可以进行如下操作加载数据：\n",
    "\n",
    "1. 运行cell 2\n",
    "2. 3-5秒后停止运行（点击上方工具栏中的黑色正方形按钮）\n",
    "3. 运行cell 3，并等待运行完成\n",
    "4. 重新运行cell 2\n",
    "\n",
    "完成上述操作后，即加载数据成功。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 2\n",
    "# 加载数据\n",
    "nb_classes = 10\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "X_train = X_train.astype(\"float32\")\n",
    "X_test = X_test.astype(\"float32\")\n",
    "# 幅度缩放\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 3\n",
    "! cp /data/Deep_learning/cifar-10-batches-py.tar.gz  ~/.keras/datasets/cifar-10-batches-py.tar.gz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.数据增强\n",
    "#### \\[稀牛学院 x 网易云课程\\]《深度学习工程师(实战)》课程资料 by [@寒小阳](https://blog.csdn.net/han_xiaoyang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了提高模型的泛化能力，我们使用到了一个叫做`数据增强`的处理，在keras中可以通过ImageDataGenerator完成，详细的可以参见[Image Data Generator](http://keras.io/preprocessing/image/)。这个处理会对输入的图片数据进行例如旋转、平移、截取、水平、垂直翻转等处理，并不改变图像内容，但是能扩量计算机没有看过的数据，提高模型的泛化能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 提示：这个部分可能计算量比较大...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "generated_images = ImageDataGenerator(\n",
    "    featurewise_center=True,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=True,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images\n",
    "\n",
    "generated_images.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们每次从`ImageDataGenerator`中取出500张做过数据增强的图片用于一个批次的训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = generated_images.flow(X_train, Y_train, batch_size=500, shuffle=True)\n",
    "X_batch, Y_batch = next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 32, 32, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.构建模型\n",
    "#### \\[稀牛学院 x 网易云课程\\]《深度学习工程师(实战)》课程资料 by [@寒小阳](https://blog.csdn.net/han_xiaoyang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epoch = 10  # 迭代轮次\n",
    "batch_size = 128 # 一个batch的数据量\n",
    "nb_filters = 32 # 卷积层filter的个数\n",
    "nb_pool = 2 # 池化层的kernel size\n",
    "nb_conv = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(nb_filters, (nb_conv, nb_conv),padding='same',input_shape=X_batch.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(2,2))\n",
    "model.add(Conv2D(nb_filters, (nb_conv, nb_conv)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(2,2))\n",
    "model.add(Conv2D(nb_filters, (nb_conv, nb_conv)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(2,2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.模型训练与评估\n",
    "#### \\[稀牛学院 x 网易云课程\\]《深度学习工程师(实战)》课程资料 by [@寒小阳](https://blog.csdn.net/han_xiaoyang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 [==============================] - 28s 280ms/step - loss: 1.0306 - acc: 0.6453\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 28s 281ms/step - loss: 1.0193 - acc: 0.6443\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 28s 280ms/step - loss: 1.0274 - acc: 0.6427\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 28s 280ms/step - loss: 1.0101 - acc: 0.6502\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 28s 283ms/step - loss: 1.0137 - acc: 0.6487\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 28s 284ms/step - loss: 1.0140 - acc: 0.6468\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 28s 283ms/step - loss: 1.0115 - acc: 0.6494\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 28s 283ms/step - loss: 0.9941 - acc: 0.6544\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 28s 282ms/step - loss: 0.9983 - acc: 0.6507\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 29s 285ms/step - loss: 0.9959 - acc: 0.6571\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 28s 279ms/step - loss: 0.9920 - acc: 0.6548\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 28s 282ms/step - loss: 0.9835 - acc: 0.6596\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 28s 283ms/step - loss: 0.9878 - acc: 0.6549\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 28s 285ms/step - loss: 0.9804 - acc: 0.6615\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 28s 280ms/step - loss: 0.9812 - acc: 0.6590\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 28s 281ms/step - loss: 0.9742 - acc: 0.6672\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 29s 286ms/step - loss: 0.9721 - acc: 0.6630\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 29s 287ms/step - loss: 0.9712 - acc: 0.6624\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 28s 285ms/step - loss: 0.9721 - acc: 0.6628\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 28s 283ms/step - loss: 0.9653 - acc: 0.6662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff348caec50>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(gen, epochs=20, steps_per_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 4s 82us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.211750121612549, 0.30754]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 84us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.2134314895629883, 0.3077]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 版权归 © 稀牛学院 所有 保留所有权利\n",
    "![](./img/xiniu_neteasy.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
