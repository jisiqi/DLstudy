{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-dac76a229d56>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From <ipython-input-2-dac76a229d56>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From F:\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From F:\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From F:\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "WARNING:tensorflow:From F:\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From F:\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "WARNING:tensorflow:From F:\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From F:\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From F:\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From F:\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From F:\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "#load dataset\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From F:\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From F:\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-3-d8ffa40bfc88>:110: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From <ipython-input-3-d8ffa40bfc88>:110: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From <ipython-input-3-d8ffa40bfc88>:127: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-3-d8ffa40bfc88>:127: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Iter0test accuracy0.0926training accuracy0.1003\n",
      "Iter0test accuracy0.0926training accuracy0.1003\n",
      "Iter100test accuracy0.6453training accuracy0.1013\n",
      "Iter100test accuracy0.6453training accuracy0.1013\n",
      "Iter200test accuracy0.671training accuracy0.0978\n",
      "Iter200test accuracy0.671training accuracy0.0978\n",
      "Iter300test accuracy0.6772training accuracy0.1089\n",
      "Iter300test accuracy0.6772training accuracy0.1089\n",
      "Iter400test accuracy0.6801training accuracy0.0969\n",
      "Iter400test accuracy0.6801training accuracy0.0969\n",
      "Iter500test accuracy0.7747training accuracy0.1058\n",
      "Iter500test accuracy0.7747training accuracy0.1058\n",
      "Iter600test accuracy0.846training accuracy0.1022\n",
      "Iter600test accuracy0.846training accuracy0.1022\n",
      "Iter700test accuracy0.8624training accuracy0.0963\n",
      "Iter700test accuracy0.8624training accuracy0.0963\n",
      "Iter800test accuracy0.8685training accuracy0.0995\n",
      "Iter800test accuracy0.8685training accuracy0.0995\n",
      "Iter900test accuracy0.8712training accuracy0.0976\n",
      "Iter900test accuracy0.8712training accuracy0.0976\n",
      "Iter1000test accuracy0.8719training accuracy0.1013\n",
      "Iter1000test accuracy0.8719training accuracy0.1013\n"
     ]
    }
   ],
   "source": [
    "# 每个批次的大小\n",
    "batch_size = 100\n",
    "#批次的个数\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "\n",
    "#参数概要\n",
    "def variable_summaries(var):\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean',mean) \n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_mean(tf.square(var-mean)))\n",
    "        tf.summary.scalar('stddev',stddev)\n",
    "        tf.summary.scalar('max',tf.reduce_max(var))\n",
    "        tf.summary.scalar('min',tf.reduce_min(var))\n",
    "        tf.summary.histogram('histogram',var)\n",
    "        \n",
    "        \n",
    "#初始化权重\n",
    "def weight_variable(shape,name):\n",
    "    initial = tf.truncated_normal(shape,stddev=0.1)\n",
    "    return tf.Variable(initial,name=name)\n",
    "\n",
    "#初始化偏置\n",
    "def bias_variable(shape,name):\n",
    "    initial = tf.constant(0.1,shape=shape)\n",
    "    return tf.Variable(initial,name=name)\n",
    "\n",
    "\n",
    "\n",
    "#卷积层\n",
    "def conv2d(x,W):\n",
    "    # x input tensor of shape [batch,in_height,in_width,in_channels]\n",
    "    # W filter /kernel tensor of shape[filter_height,filter_width,in_channels,out_channels]\n",
    "    # strides[0]=strides[3]=1, strides[1]代表x方向上的步长，strides[2]代表y方向上的步长\n",
    "    # padding: string from \"SAME\",\"VALID\"\n",
    "    return tf.nn.conv2d(x,W,strides=[1,1,1,1,],padding=\"SAME\")\n",
    "\n",
    "#池化层\n",
    "def max_pool_2x2(x):\n",
    "    #ksize[1,x,y,1]\n",
    "    return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1,],padding=\"SAME\")\n",
    "\n",
    "\n",
    "#命名空间\n",
    "with tf.name_scope('input'):\n",
    "    x = tf.placeholder(tf.float32, [None,784],name='x-input')\n",
    "    y = tf.placeholder(tf.float32, [None,10],name='y-input')\n",
    "    \n",
    "    with tf.name_scope('x_image'):\n",
    "        #改变x的格式转化为4D的向量[batch,in_height,in_width,in_channels]\n",
    "        x_image = tf.reshape(x,[-1,28,28,1],name='x_image')\n",
    "        \n",
    "with tf.name_scope('Conv1'):\n",
    "    #初始化第一个卷积层的权重和偏置\n",
    "    with tf.name_scope('W_conv1'):\n",
    "        W_conv1 = weight_variable([5,5,1,32],name='W_conv1')#5*5采样窗口，32个卷积核从一个平面抽取特征\n",
    "    with tf.name_scope('b_conv1'):\n",
    "        b_conv1 = bias_variable([32],name='b_conv1')#每一个卷积核一个偏置值\n",
    "        \n",
    "    #把x_image和权值向量进行卷积，再加上偏置值，然后应用于relu激活函数\n",
    "    with tf.name_scope('conv2d_1'):\n",
    "        conv2d_1 = conv2d(x_image,W_conv1) + b_conv1\n",
    "    with tf.name_scope('relu'):\n",
    "        h_conv1 = tf.nn.relu(conv2d_1)\n",
    "    with tf.name_scope('h_pool1'):\n",
    "        h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "        \n",
    "with tf.name_scope('Conv2'):\n",
    "    #初始化第一个卷积层的权重和偏置\n",
    "    with tf.name_scope('W_conv2'):\n",
    "        W_conv2 = weight_variable([5,5,32,64],name='W_conv2')#5*5采样窗口，64个卷积核从32个平面抽取特征\n",
    "    with tf.name_scope('b_conv2'):\n",
    "        b_conv2 = bias_variable([64],name='b_conv2')#每一个卷积核一个偏置值\n",
    "        \n",
    "    #把h_pool1和权值向量进行卷积，再加上偏置值，然后应用于relu激活函数\n",
    "    with tf.name_scope('conv2d_2'):\n",
    "        conv2d_2 = conv2d(h_pool1,W_conv2) + b_conv2\n",
    "    with tf.name_scope('relu'):\n",
    "        h_conv2 = tf.nn.relu(conv2d_2)\n",
    "    with tf.name_scope('h_pool1'):\n",
    "        h_pool2 = max_pool_2x2(h_conv2)\n",
    "        \n",
    "#28*28的图片第一次卷积后不变，第一次池化后变成14*14\n",
    "#第二次卷积不变，池化后为7*7\n",
    "#得到64张7*7平面\n",
    "\n",
    "with tf.name_scope('fc1'):\n",
    "    #初始化第一个全连接层的权值\n",
    "    with tf.name_scope('W_fc1'):\n",
    "        W_fc1 = weight_variable([7*7*64,1024],name='W_fc1')#有7*7*64个神经元，全连接层有1024个神经元\n",
    "    with tf.name_scope('b_fc1'):\n",
    "        b_fc1 = bias_variable([1024],name='b_fc1')#1024节点\n",
    "        \n",
    "    #把池化层2的输出扁平为1维\n",
    "    with tf.name_scope('h2_pool2_flat'):\n",
    "        h2_pool2_flat = tf.reshape(h_pool2,[-1,7*7*64],name='h2_pool2_flat')\n",
    "    #求第一个全连接层的输出\n",
    "    with tf.name_scope('wx_plus_b1'):\n",
    "        wx_plus_b1 = tf.matmul(h2_pool2_flat,W_fc1) + b_fc1\n",
    "    with tf.name_scope('relu'):\n",
    "        h_fc1 = tf.nn.relu(wx_plus_b1)\n",
    "        \n",
    "    #keep_prob用来表示神经元的输出概率\n",
    "    with tf.name_scope('keep_prob'):\n",
    "        keep_prob = tf.placeholder(tf.float32,name='keep_prob')\n",
    "    with tf.name_scope('h_fc1_drop'):\n",
    "        h_fc1_drop = tf.nn.dropout(h_fc1,keep_prob,name='h_fc1_drop')\n",
    "\n",
    "        \n",
    "with tf.name_scope('fc2'):\n",
    "    #初始化第2个全连接层的权值\n",
    "    with tf.name_scope('W_fc2'):\n",
    "        W_fc2 = weight_variable([1024,10],name='W_fc2')\n",
    "    with tf.name_scope('b_fc2'):\n",
    "        b_fc2 = bias_variable([10],name='b_fc2')#1024节点\n",
    "    with tf.name_scope('wx_plus_b2'):\n",
    "        wx_plus_b2 = tf.matmul(h_fc1_drop,W_fc2) + b_fc2\n",
    "    with tf.name_scope('softmax'):\n",
    "        prediction = tf.nn.softmax(wx_plus_b2)    \n",
    "        \n",
    "        \n",
    "with tf.name_scope('loss'):\n",
    "    #cross entropy cost\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=prediction))\n",
    "    tf.summary.scalar('loss',loss)\n",
    "with tf.name_scope('train'):\n",
    "    #gradient descent\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "    \n",
    "\n",
    "\n",
    "with tf.name_scope('accuracy'):\n",
    "    with tf.name_scope('correct_prediction'):\n",
    "        #result is stored in a boolean list\n",
    "        correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1)) #argmax returns the position of the greatest number in a list\n",
    "    with tf.name_scope('accuracy'):\n",
    "        #find accuracy\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32)) #change correct_prediction into float 32 type\n",
    "        tf.summary.scalar('accuracy', accuracy)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#合并所有summary\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    train_writer = tf.summary.FileWriter('logs/train',sess.graph)\n",
    "    test_writer = tf.summary.FileWriter('logs/test',sess.graph)\n",
    "    writer = tf.summary.FileWriter('logs/',sess.graph)\n",
    "    for i in range(1001):\n",
    "        #训练模型\n",
    "        batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "        sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys,keep_prob:0.5})\n",
    "        #记录训练集计算的参数\n",
    "        summary = sess.run(merged,feed_dict={x:batch_xs,y:batch_ys,keep_prob:1.0})\n",
    "        train_writer.add_summary(summary,i)\n",
    "        #记录测试集计算的参数\n",
    "        batch_xs,batch_ys = mnist.test.next_batch(batch_size)\n",
    "        summary = sess.run(merged,feed_dict={x:batch_xs,y:batch_ys,keep_prob:1.0})\n",
    "        test_writer.add_summary(summary,i)\n",
    "        \n",
    "        if i%100==0:\n",
    "            test_acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels,keep_prob:1.0})\n",
    "            train_acc = sess.run(accuracy,feed_dict={x:mnist.train.images[:10000],y:mnist.test.labels[:10000],keep_prob:1.0})\n",
    "            print(\"Iter\"+str(i)+\"test accuracy\"+str(test_acc)+\"training accuracy\"+str(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
